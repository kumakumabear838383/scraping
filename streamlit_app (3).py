import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
from urllib.parse import urljoin, urlparse
import re

def scrape_data(url, max_pages, delay_range, item_delay_range, css_selectors, auto_stop_enabled, auto_stop_threshold):
    """
    æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹

    Args:
        url: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡ã®URL
        max_pages: æœ€å¤§ãƒšãƒ¼ã‚¸æ•°
        delay_range: ãƒšãƒ¼ã‚¸é–“ã®å¾…æ©Ÿæ™‚é–“ç¯„å›² (min, max)
        item_delay_range: ã‚¢ã‚¤ãƒ†ãƒ é–“ã®å¾…æ©Ÿæ™‚é–“ç¯„å›² (min, max)
        css_selectors: CSSã‚»ãƒ¬ã‚¯ã‚¿ã®è¾æ›¸
        auto_stop_enabled: è‡ªå‹•çµ‚äº†æ©Ÿèƒ½ã®æœ‰åŠ¹/ç„¡åŠ¹
        auto_stop_threshold: è‡ªå‹•çµ‚äº†ã®é–¾å€¤
    """
    all_data = []
    base_url = f"{urlparse(url).scheme}://{urlparse(url).netloc}"

    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤ºç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ
    progress_container = st.container()

    for page in range(1, max_pages + 1):
        with progress_container:
            st.write(f"ğŸ“„ ãƒšãƒ¼ã‚¸ {page}/{max_pages} ã‚’å‡¦ç†ä¸­...")

        try:
            # ãƒšãƒ¼ã‚¸ã®HTMLã‚’å–å¾—
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')

            # ã‚¢ã‚¤ãƒ†ãƒ ã‚’å–å¾—
            items = soup.select(css_selectors['item'])

            if not items:
                st.warning(f"ãƒšãƒ¼ã‚¸ {page} ã§ã‚¢ã‚¤ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                break

            page_data = []

            # å„ã‚¢ã‚¤ãƒ†ãƒ ã‚’å‡¦ç†
            for i, item in enumerate(items, 1):
                try:
                    # ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                    title = item.select_one(css_selectors['title'])
                    title_text = title.get_text(strip=True) if title else "ã‚¿ã‚¤ãƒˆãƒ«ãªã—"

                    link = item.select_one(css_selectors['link'])
                    link_url = ""
                    if link:
                        href = link.get('href')
                        if href:
                            link_url = urljoin(base_url, href)

                    # ãã®ä»–ã®æƒ…å ±ã‚’æŠ½å‡º
                    other_info = {}
                    for key, selector in css_selectors.items():
                        if key not in ['item', 'title', 'link', 'next_page']:
                            element = item.select_one(selector)
                            if element:
                                other_info[key] = element.get_text(strip=True)

                    # ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                    item_data = {
                        'ãƒšãƒ¼ã‚¸': page,
                        'ã‚¢ã‚¤ãƒ†ãƒ ç•ªå·': i,
                        'ã‚¿ã‚¤ãƒˆãƒ«': title_text,
                        'ãƒªãƒ³ã‚¯': link_url,
                        **other_info
                    }
                    page_data.append(item_data)

                    # ã‚¢ã‚¤ãƒ†ãƒ é–“ã®å¾…æ©Ÿæ™‚é–“
                    if i < len(items):  # æœ€å¾Œã®ã‚¢ã‚¤ãƒ†ãƒ ã§ã¯å¾…æ©Ÿã—ãªã„
                        item_delay = random.uniform(item_delay_range[0], item_delay_range[1])
                        with progress_container:
                            st.write(f"â³ ã‚¢ã‚¤ãƒ†ãƒ å‡¦ç†å¾…æ©Ÿä¸­... {item_delay:.1f}ç§’")
                        time.sleep(item_delay)

                except Exception as e:
                    st.warning(f"ã‚¢ã‚¤ãƒ†ãƒ  {i} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    continue

            all_data.extend(page_data)

            with progress_container:
                st.write(f"âœ… ãƒšãƒ¼ã‚¸ {page} å®Œäº†: {len(page_data)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")

            # è‡ªå‹•çµ‚äº†æ©Ÿèƒ½ã®ãƒã‚§ãƒƒã‚¯
            if auto_stop_enabled and len(page_data) < auto_stop_threshold:
                st.info(f"è‡ªå‹•çµ‚äº†: ãƒšãƒ¼ã‚¸ {page} ã§å–å¾—ãƒ‡ãƒ¼ã‚¿ãŒ {auto_stop_threshold} ä»¶æœªæº€ã®ãŸã‚çµ‚äº†ã—ã¾ã—ãŸã€‚")
                break

            # æ¬¡ã®ãƒšãƒ¼ã‚¸ã®URLã‚’å–å¾—
            if page < max_pages:
                next_link = soup.select_one(css_selectors['next_page'])
                if next_link:
                    next_href = next_link.get('href')
                    if next_href:
                        url = urljoin(base_url, next_href)
                    else:
                        st.warning(f"ãƒšãƒ¼ã‚¸ {page} ã§æ¬¡ã®ãƒšãƒ¼ã‚¸ã®ãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                        break
                else:
                    st.warning(f"ãƒšãƒ¼ã‚¸ {page} ã§æ¬¡ã®ãƒšãƒ¼ã‚¸ã®ã‚»ãƒ¬ã‚¯ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    break

                # ãƒšãƒ¼ã‚¸é–“ã®å¾…æ©Ÿæ™‚é–“
                page_delay = random.uniform(delay_range[0], delay_range[1])
                with progress_container:
                    st.write(f"â³ ãƒšãƒ¼ã‚¸é–“å¾…æ©Ÿä¸­... {page_delay:.1f}ç§’")
                time.sleep(page_delay)

        except requests.RequestException as e:
            st.error(f"ãƒšãƒ¼ã‚¸ {page} ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            break
        except Exception as e:
            st.error(f"ãƒšãƒ¼ã‚¸ {page} ã®å‡¦ç†ä¸­ã«äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            break

    return all_data

def main():
    st.set_page_config(
        page_title="Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«",
        page_icon="ğŸ•·ï¸",
        layout="wide"
    )

    st.title("ğŸ•·ï¸ Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«")
    st.markdown("---")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")

        # åŸºæœ¬è¨­å®š
        st.subheader("ğŸŒ åŸºæœ¬è¨­å®š")
        url = st.text_input(
            "ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡URL",
            placeholder="https://example.com",
            help="ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’é–‹å§‹ã™ã‚‹ãƒšãƒ¼ã‚¸ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        )

        max_pages = st.number_input(
            "æœ€å¤§ãƒšãƒ¼ã‚¸æ•°",
            min_value=1,
            max_value=100,
            value=5,
            help="ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã™ã‚‹æœ€å¤§ãƒšãƒ¼ã‚¸æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„"
        )

        # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›è¨­å®š
        st.subheader("ğŸ›¡ï¸ ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›è¨­å®š")
        st.markdown("*ã‚µãƒ¼ãƒãƒ¼ã¸ã®è² è·ã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®å¾…æ©Ÿæ™‚é–“è¨­å®š*")

        # ãƒšãƒ¼ã‚¸é–“å¾…æ©Ÿæ™‚é–“
        st.markdown("**ãƒšãƒ¼ã‚¸é–“å¾…æ©Ÿæ™‚é–“**")
        col1, col2 = st.columns(2)
        with col1:
            min_delay = st.number_input(
                "æœ€å°å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰",
                min_value=0.1,
                max_value=10.0,
                value=1.0,
                step=0.1,
                key="page_min_delay",
                help="ãƒšãƒ¼ã‚¸é–“ã®æœ€å°å¾…æ©Ÿæ™‚é–“"
            )
        with col2:
            max_delay = st.number_input(
                "æœ€å¤§å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰",
                min_value=0.1,
                max_value=10.0,
                value=3.0,
                step=0.1,
                key="page_max_delay",
                help="ãƒšãƒ¼ã‚¸é–“ã®æœ€å¤§å¾…æ©Ÿæ™‚é–“"
            )

        # ã‚¢ã‚¤ãƒ†ãƒ é–“å¾…æ©Ÿæ™‚é–“
        st.markdown("**ã‚¢ã‚¤ãƒ†ãƒ é–“å¾…æ©Ÿæ™‚é–“**")
        col3, col4 = st.columns(2)
        with col3:
            min_item_delay = st.number_input(
                "æœ€å°å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰",
                min_value=0.0,
                max_value=5.0,
                value=0.2,
                step=0.1,
                key="item_min_delay",
                help="ã‚¢ã‚¤ãƒ†ãƒ é–“ã®æœ€å°å¾…æ©Ÿæ™‚é–“"
            )
        with col4:
            max_item_delay = st.number_input(
                "æœ€å¤§å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰",
                min_value=0.0,
                max_value=5.0,
                value=0.5,
                step=0.1,
                key="item_max_delay",
                help="ã‚¢ã‚¤ãƒ†ãƒ é–“ã®æœ€å¤§å¾…æ©Ÿæ™‚é–“"
            )

        # å¾…æ©Ÿæ™‚é–“ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        if min_delay > max_delay:
            st.error("âš ï¸ ãƒšãƒ¼ã‚¸é–“å¾…æ©Ÿæ™‚é–“: æœ€å°å€¤ãŒæœ€å¤§å€¤ã‚’ä¸Šå›ã£ã¦ã„ã¾ã™")
        if min_item_delay > max_item_delay:
            st.error("âš ï¸ ã‚¢ã‚¤ãƒ†ãƒ é–“å¾…æ©Ÿæ™‚é–“: æœ€å°å€¤ãŒæœ€å¤§å€¤ã‚’ä¸Šå›ã£ã¦ã„ã¾ã™")

        # è‡ªå‹•çµ‚äº†è¨­å®š
        st.subheader("ğŸ”„ è‡ªå‹•çµ‚äº†è¨­å®š")
        auto_stop_enabled = st.checkbox(
            "è‡ªå‹•çµ‚äº†æ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã™ã‚‹",
            value=True,
            help="å–å¾—ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„ãƒšãƒ¼ã‚¸ã§è‡ªå‹•çš„ã«çµ‚äº†ã—ã¾ã™"
        )

        auto_stop_threshold = st.number_input(
            "è‡ªå‹•çµ‚äº†ã®é–¾å€¤",
            min_value=1,
            max_value=50,
            value=5,
            disabled=not auto_stop_enabled,
            help="ã“ã®æ•°å€¤æœªæº€ã®ãƒ‡ãƒ¼ã‚¿ã—ã‹å–å¾—ã§ããªã„å ´åˆã«çµ‚äº†ã—ã¾ã™"
        )

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("ğŸ¯ CSSã‚»ãƒ¬ã‚¯ã‚¿è¨­å®š")

        # å¿…é ˆã‚»ãƒ¬ã‚¯ã‚¿
        st.markdown("**å¿…é ˆã‚»ãƒ¬ã‚¯ã‚¿**")
        item_selector = st.text_input(
            "ã‚¢ã‚¤ãƒ†ãƒ ã‚»ãƒ¬ã‚¯ã‚¿",
            placeholder=".item, .product, .post",
            help="å„ã‚¢ã‚¤ãƒ†ãƒ ï¼ˆå•†å“ã€è¨˜äº‹ãªã©ï¼‰ã‚’å›²ã‚€è¦ç´ ã®CSSã‚»ãƒ¬ã‚¯ã‚¿"
        )

        title_selector = st.text_input(
            "ã‚¿ã‚¤ãƒˆãƒ«ã‚»ãƒ¬ã‚¯ã‚¿",
            placeholder="h2, .title, .name",
            help="ã‚¿ã‚¤ãƒˆãƒ«ã‚’å«ã‚€è¦ç´ ã®CSSã‚»ãƒ¬ã‚¯ã‚¿"
        )

        link_selector = st.text_input(
            "ãƒªãƒ³ã‚¯ã‚»ãƒ¬ã‚¯ã‚¿",
            placeholder="a, .link",
            help="è©³ç´°ãƒšãƒ¼ã‚¸ã¸ã®ãƒªãƒ³ã‚¯ã‚’å«ã‚€è¦ç´ ã®CSSã‚»ãƒ¬ã‚¯ã‚¿"
        )

        next_page_selector = st.text_input(
            "æ¬¡ãƒšãƒ¼ã‚¸ã‚»ãƒ¬ã‚¯ã‚¿",
            placeholder=".next, .pagination a[rel='next']",
            help="æ¬¡ã®ãƒšãƒ¼ã‚¸ã¸ã®ãƒªãƒ³ã‚¯ã‚’å«ã‚€è¦ç´ ã®CSSã‚»ãƒ¬ã‚¯ã‚¿"
        )

        # è¿½åŠ ã‚»ãƒ¬ã‚¯ã‚¿
        st.markdown("**è¿½åŠ ã‚»ãƒ¬ã‚¯ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰**")
        additional_selectors = {}

        num_additional = st.number_input(
            "è¿½åŠ ã‚»ãƒ¬ã‚¯ã‚¿æ•°",
            min_value=0,
            max_value=10,
            value=0,
            help="ä¾¡æ ¼ã€è©•ä¾¡ã€èª¬æ˜æ–‡ãªã©ã€è¿½åŠ ã§å–å¾—ã—ãŸã„æƒ…å ±ã®æ•°"
        )

        for i in range(num_additional):
            col_name, col_selector = st.columns([1, 2])
            with col_name:
                field_name = st.text_input(
                    f"ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å {i+1}",
                    placeholder="ä¾¡æ ¼, è©•ä¾¡, èª¬æ˜",
                    key=f"field_name_{i}"
                )
            with col_selector:
                field_selector = st.text_input(
                    f"ã‚»ãƒ¬ã‚¯ã‚¿ {i+1}",
                    placeholder=".price, .rating, .description",
                    key=f"field_selector_{i}"
                )

            if field_name and field_selector:
                additional_selectors[field_name] = field_selector

    with col2:
        st.subheader("ğŸ“Š ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»å®Ÿè¡Œ")

        # è¨­å®šã®ç¢ºèª
        if url and item_selector and title_selector and link_selector and next_page_selector:
            st.success("âœ… å¿…é ˆé …ç›®ãŒã™ã¹ã¦å…¥åŠ›ã•ã‚Œã¦ã„ã¾ã™")

            # è¨­å®šã‚µãƒãƒªãƒ¼
            with st.expander("è¨­å®šã‚µãƒãƒªãƒ¼", expanded=True):
                st.write(f"**URL:** {url}")
                st.write(f"**æœ€å¤§ãƒšãƒ¼ã‚¸æ•°:** {max_pages}")
                st.write(f"**ãƒšãƒ¼ã‚¸é–“å¾…æ©Ÿ:** {min_delay}ã€œ{max_delay}ç§’")
                st.write(f"**ã‚¢ã‚¤ãƒ†ãƒ é–“å¾…æ©Ÿ:** {min_item_delay}ã€œ{max_item_delay}ç§’")
                st.write(f"**è‡ªå‹•çµ‚äº†:** {'æœ‰åŠ¹' if auto_stop_enabled else 'ç„¡åŠ¹'}")
                if auto_stop_enabled:
                    st.write(f"**çµ‚äº†é–¾å€¤:** {auto_stop_threshold}ä»¶")
                st.write(f"**è¿½åŠ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰:** {len(additional_selectors)}å€‹")

            # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œãƒœã‚¿ãƒ³
            if st.button("ğŸš€ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹", type="primary", use_container_width=True):
                # CSSã‚»ãƒ¬ã‚¯ã‚¿ã‚’ã¾ã¨ã‚ã‚‹
                css_selectors = {
                    'item': item_selector,
                    'title': title_selector,
                    'link': link_selector,
                    'next_page': next_page_selector,
                    **additional_selectors
                }

                # å¾…æ©Ÿæ™‚é–“ã®ç¯„å›²
                delay_range = (min_delay, max_delay)
                item_delay_range = (min_item_delay, max_item_delay)

                # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
                with st.spinner("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­..."):
                    try:
                        data = scrape_data(
                            url, 
                            max_pages, 
                            delay_range, 
                            item_delay_range,
                            css_selectors, 
                            auto_stop_enabled, 
                            auto_stop_threshold
                        )

                        if data:
                            st.success(f"âœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†ï¼ {len(data)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")

                            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
                            df = pd.DataFrame(data)

                            # çµæœã®è¡¨ç¤º
                            st.subheader("ğŸ“‹ å–å¾—ãƒ‡ãƒ¼ã‚¿")
                            st.dataframe(df, use_container_width=True)

                            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                            csv = df.to_csv(index=False, encoding='utf-8-sig')
                            st.download_button(
                                label="ğŸ“¥ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=csv,
                                file_name=f"scraped_data_{int(time.time())}.csv",
                                mime="text/csv",
                                use_container_width=True
                            )

                            # çµ±è¨ˆæƒ…å ±
                            with st.expander("ğŸ“ˆ çµ±è¨ˆæƒ…å ±"):
                                st.write(f"**ç·ãƒ‡ãƒ¼ã‚¿æ•°:** {len(data)}")
                                st.write(f"**å‡¦ç†ãƒšãƒ¼ã‚¸æ•°:** {df['ãƒšãƒ¼ã‚¸'].nunique()}")
                                st.write(f"**å¹³å‡ã‚¢ã‚¤ãƒ†ãƒ æ•°/ãƒšãƒ¼ã‚¸:** {len(data) / df['ãƒšãƒ¼ã‚¸'].nunique():.1f}")

                                # ãƒšãƒ¼ã‚¸åˆ¥ãƒ‡ãƒ¼ã‚¿æ•°
                                page_counts = df['ãƒšãƒ¼ã‚¸'].value_counts().sort_index()
                                st.write("**ãƒšãƒ¼ã‚¸åˆ¥ãƒ‡ãƒ¼ã‚¿æ•°:**")
                                st.bar_chart(page_counts)

                        else:
                            st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚CSSã‚»ãƒ¬ã‚¯ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

                    except Exception as e:
                        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

        else:
            st.warning("âš ï¸ å¿…é ˆé …ç›®ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            missing_items = []
            if not url:
                missing_items.append("URL")
            if not item_selector:
                missing_items.append("ã‚¢ã‚¤ãƒ†ãƒ ã‚»ãƒ¬ã‚¯ã‚¿")
            if not title_selector:
                missing_items.append("ã‚¿ã‚¤ãƒˆãƒ«ã‚»ãƒ¬ã‚¯ã‚¿")
            if not link_selector:
                missing_items.append("ãƒªãƒ³ã‚¯ã‚»ãƒ¬ã‚¯ã‚¿")
            if not next_page_selector:
                missing_items.append("æ¬¡ãƒšãƒ¼ã‚¸ã‚»ãƒ¬ã‚¯ã‚¿")

            st.write(f"**æœªå…¥åŠ›é …ç›®:** {', '.join(missing_items)}")

    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: #666;'>
            <p>ğŸ•·ï¸ Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ„ãƒ¼ãƒ« | 
            ã‚µãƒ¼ãƒãƒ¼è² è·ã‚’è€ƒæ…®ã—ãŸå®‰å…¨ãªã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å¿ƒãŒã‘ã¾ã—ã‚‡ã†</p>
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()
